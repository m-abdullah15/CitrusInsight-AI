{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67ac4c04-538e-4d5f-823c-50514a11ef4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4689 images belonging to 10 classes.\n",
      "Found 1170 images belonging to 10 classes.\n",
      "Epoch 1/5\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2100s\u001b[0m 14s/step - accuracy: 0.1339 - loss: 2.2944 - val_accuracy: 0.1496 - val_loss: 2.2889\n",
      "Epoch 2/5\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1251s\u001b[0m 9s/step - accuracy: 0.1741 - loss: 2.2508 - val_accuracy: 0.1983 - val_loss: 2.2703\n",
      "Epoch 3/5\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1300s\u001b[0m 9s/step - accuracy: 0.1974 - loss: 2.2015 - val_accuracy: 0.2085 - val_loss: 2.2538\n",
      "Epoch 4/5\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1244s\u001b[0m 8s/step - accuracy: 0.1917 - loss: 2.1641 - val_accuracy: 0.2265 - val_loss: 2.2563\n",
      "Epoch 5/5\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1218s\u001b[0m 8s/step - accuracy: 0.2115 - loss: 2.1481 - val_accuracy: 0.1863 - val_loss: 2.2691\n",
      "Epoch 1/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2087s\u001b[0m 14s/step - accuracy: 0.2404 - loss: 2.0639 - val_accuracy: 0.1239 - val_loss: 2.5749\n",
      "Epoch 2/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2045s\u001b[0m 14s/step - accuracy: 0.4512 - loss: 1.5963 - val_accuracy: 0.4675 - val_loss: 1.6359\n",
      "Epoch 3/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2057s\u001b[0m 14s/step - accuracy: 0.5590 - loss: 1.2425 - val_accuracy: 0.5530 - val_loss: 1.1280\n",
      "Epoch 4/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2058s\u001b[0m 14s/step - accuracy: 0.6544 - loss: 1.0006 - val_accuracy: 0.5761 - val_loss: 1.3596\n",
      "Epoch 5/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2047s\u001b[0m 14s/step - accuracy: 0.7016 - loss: 0.8417 - val_accuracy: 0.5376 - val_loss: 1.4999\n",
      "Epoch 6/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2052s\u001b[0m 14s/step - accuracy: 0.7634 - loss: 0.7059 - val_accuracy: 0.8299 - val_loss: 0.4180\n",
      "Epoch 7/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2050s\u001b[0m 14s/step - accuracy: 0.8186 - loss: 0.5474 - val_accuracy: 0.8453 - val_loss: 0.4928\n",
      "Epoch 8/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2047s\u001b[0m 14s/step - accuracy: 0.8356 - loss: 0.4886 - val_accuracy: 0.7641 - val_loss: 0.8334\n",
      "Epoch 9/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2039s\u001b[0m 14s/step - accuracy: 0.8722 - loss: 0.3983 - val_accuracy: 0.8607 - val_loss: 0.3594\n",
      "Epoch 10/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2045s\u001b[0m 14s/step - accuracy: 0.8956 - loss: 0.3353 - val_accuracy: 0.8274 - val_loss: 0.4525\n",
      "Epoch 11/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2056s\u001b[0m 14s/step - accuracy: 0.9060 - loss: 0.2986 - val_accuracy: 0.9103 - val_loss: 0.2530\n",
      "Epoch 12/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2047s\u001b[0m 14s/step - accuracy: 0.9300 - loss: 0.2463 - val_accuracy: 0.8632 - val_loss: 0.3718\n",
      "Epoch 13/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2054s\u001b[0m 14s/step - accuracy: 0.9401 - loss: 0.1987 - val_accuracy: 0.8897 - val_loss: 0.3075\n",
      "Epoch 14/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2123s\u001b[0m 14s/step - accuracy: 0.9480 - loss: 0.1763 - val_accuracy: 0.9000 - val_loss: 0.2786\n",
      "Epoch 15/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2225s\u001b[0m 15s/step - accuracy: 0.9590 - loss: 0.1494 - val_accuracy: 0.8838 - val_loss: 0.3202\n",
      "Epoch 16/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2181s\u001b[0m 15s/step - accuracy: 0.9509 - loss: 0.1570 - val_accuracy: 0.9325 - val_loss: 0.2675\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 6s/step\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "   Citrus canker       0.06      0.05      0.05       117\n",
      " Citrus greening       0.12      0.12      0.12       120\n",
      "Citrus mealybugs       0.13      0.15      0.14       120\n",
      "        Die back       0.13      0.12      0.12       117\n",
      " Foliage damaged       0.10      0.07      0.08       120\n",
      "    Healthy leaf       0.09      0.09      0.09       120\n",
      "  Powdery mildew       0.10      0.10      0.10       120\n",
      "       Shot hole       0.13      0.12      0.13       112\n",
      "  Spiny whitefly       0.09      0.12      0.10       120\n",
      "   Yellow leaves       0.07      0.08      0.07       104\n",
      "\n",
      "        accuracy                           0.10      1170\n",
      "       macro avg       0.10      0.10      0.10      1170\n",
      "    weighted avg       0.10      0.10      0.10      1170\n",
      "\n",
      "Overall Accuracy: 10.17%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "DATASET_PATH = \"F:\\\\citrus_dataset\"\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "CLASS_NAMES = [\n",
    "    \"Citrus canker\", \"Citrus greening\", \"Citrus mealybugs\", \"Die back\",\n",
    "    \"Foliage damaged\", \"Healthy leaf\", \"Powdery mildew\", \"Shot hole\",\n",
    "    \"Spiny whitefly\", \"Yellow leaves\"\n",
    "]\n",
    "\n",
    "# Data Preprocessing\n",
    "data_gen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    validation_split=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_gen = data_gen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_gen = data_gen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Load DenseNet121 base model with only 80 layers\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model = Model(inputs=base_model.input, outputs=base_model.layers[79].output)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(len(CLASS_NAMES), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=5,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Unfreeze all layers for fine-tuning\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile the model with a lower learning rate\n",
    "optimizer = Adam(learning_rate=LEARNING_RATE / 10)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune the model\n",
    "history_fine_tune = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "val_gen.reset()\n",
    "y_true = val_gen.classes\n",
    "y_pred = model.predict(val_gen)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred_classes, target_names=CLASS_NAMES))\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "print(f\"Overall Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "save_path = os.path.expanduser(r'C:/Users/abdju/OneDrive/Desktop/model/citrus_disease_model_densenet2.keras')\n",
    "model.save(save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
